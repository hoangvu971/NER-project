{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/synthetic-pii-ner.json'\n",
    "MODEL_PATH = '../models/gliner_medium-v2.1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-08-18 03:33:09--  https://huggingface.co/datasets/urchade/synthetic-pii-ner-mistral-v1/resolve/main/data.json\n",
      "Resolving huggingface.co (huggingface.co)... 3.162.58.119, 3.162.58.28, 3.162.58.5, ...\n",
      "Connecting to huggingface.co (huggingface.co)|3.162.58.119|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs-us-1.huggingface.co/repos/57/a8/57a8ec4f4ec288845876da262e329709a3abab15f5604211687806ff1c31f16f/78680af45ca6b1175c502db2eec441933de7383f440fc0f0bae46a72be13c0c7?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27data.json%3B+filename%3D%22data.json%22%3B&response-content-type=application%2Fjson&Expires=1724211212&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNDIxMTIxMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzU3L2E4LzU3YThlYzRmNGVjMjg4ODQ1ODc2ZGEyNjJlMzI5NzA5YTNhYmFiMTVmNTYwNDIxMTY4NzgwNmZmMWMzMWYxNmYvNzg2ODBhZjQ1Y2E2YjExNzVjNTAyZGIyZWVjNDQxOTMzZGU3MzgzZjQ0MGZjMGYwYmFlNDZhNzJiZTEzYzBjNz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=epXcm2zDfJ%7E8mDbyhRS3wwQCCpgr6zP9ryw9RrImXLYeLriy2pzN%7EIiOBEw9f2AXi09bLhGsGJy4M0%7EhHgRbUAybWWb0U1hmfo7JLELK9OugQZLo0oAMPML5aAmDUH4bsMsMusDK7AoytHOmD1wo7kqoICwhnBa9lKzW%7ENAE58Tah9W-%7EO0yzr0o4pP0vf%7Elo5cV9tsxJe5VvEgZamHbZ51v32wnVG4ombQUlz0a-13-tQMOTK1u2C824xb8lR%7EfCTtHaY8GbAFeuWQcDuxfXt3reAs3WdeLvIwyk8IuyTaeJWIOxPH2qR0GbF1FTV5AiO8oyiA-OGHpXQunAdzIIg__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
      "--2024-08-18 03:33:09--  https://cdn-lfs-us-1.huggingface.co/repos/57/a8/57a8ec4f4ec288845876da262e329709a3abab15f5604211687806ff1c31f16f/78680af45ca6b1175c502db2eec441933de7383f440fc0f0bae46a72be13c0c7?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27data.json%3B+filename%3D%22data.json%22%3B&response-content-type=application%2Fjson&Expires=1724211212&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNDIxMTIxMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzU3L2E4LzU3YThlYzRmNGVjMjg4ODQ1ODc2ZGEyNjJlMzI5NzA5YTNhYmFiMTVmNTYwNDIxMTY4NzgwNmZmMWMzMWYxNmYvNzg2ODBhZjQ1Y2E2YjExNzVjNTAyZGIyZWVjNDQxOTMzZGU3MzgzZjQ0MGZjMGYwYmFlNDZhNzJiZTEzYzBjNz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=epXcm2zDfJ%7E8mDbyhRS3wwQCCpgr6zP9ryw9RrImXLYeLriy2pzN%7EIiOBEw9f2AXi09bLhGsGJy4M0%7EhHgRbUAybWWb0U1hmfo7JLELK9OugQZLo0oAMPML5aAmDUH4bsMsMusDK7AoytHOmD1wo7kqoICwhnBa9lKzW%7ENAE58Tah9W-%7EO0yzr0o4pP0vf%7Elo5cV9tsxJe5VvEgZamHbZ51v32wnVG4ombQUlz0a-13-tQMOTK1u2C824xb8lR%7EfCTtHaY8GbAFeuWQcDuxfXt3reAs3WdeLvIwyk8IuyTaeJWIOxPH2qR0GbF1FTV5AiO8oyiA-OGHpXQunAdzIIg__&Key-Pair-Id=K24J24Z295AEI9\n",
      "Resolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 54.230.71.5, 54.230.71.85, 54.230.71.77, ...\n",
      "Connecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|54.230.71.5|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 23300735 (22M) [application/json]\n",
      "Saving to: ‘data.json’\n",
      "\n",
      "data.json           100%[===================>]  22.22M  12.2MB/s    in 1.8s    \n",
      "\n",
      "2024-08-18 03:33:11 (12.2 MB/s) - ‘data.json’ saved [23300735/23300735]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://huggingface.co/datasets/urchade/synthetic-pii-ner-mistral-v1/resolve/main/data.json\n",
    "! mv data.json ../data/synthetic-pii-ner.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 19635\n",
      "Dataset is shuffled...\n",
      "Dataset is splitted...\n"
     ]
    }
   ],
   "source": [
    "with open(DATA_PATH, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print('Dataset size:', len(data))\n",
    "\n",
    "random.shuffle(data)\n",
    "print('Dataset is shuffled...')\n",
    "\n",
    "train_dataset = data[:int(len(data)*0.9)]\n",
    "test_dataset = data[int(len(data)*0.9):]\n",
    "\n",
    "print('Dataset is splitted...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Juan, Pérez, ,, un, jugador, habitual, del, C...</td>\n",
       "      <td>[[0, 1, person], [7, 10, organization], [23, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Mme, Yoshiko, Nakamura, ,, agricultrice, de, ...</td>\n",
       "      <td>[[0, 2, person], [43, 45, address], [38, 41, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Prof, ., Dr, ., Abeba, Tesfamariam, ,, gebore...</td>\n",
       "      <td>[[0, 5, person], [25, 25, degree], [58, 58, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Hier, ist, das, Auszug, aus, dem, Protokoll, ...</td>\n",
       "      <td>[[24, 25, person], [32, 32, membership number]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[El, Sr, ., Juan, Pérez, ,, un, empresario, de...</td>\n",
       "      <td>[[3, 4, person], [18, 19, organization], [23, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      tokenized_text  \\\n",
       "0  [Juan, Pérez, ,, un, jugador, habitual, del, C...   \n",
       "1  [Mme, Yoshiko, Nakamura, ,, agricultrice, de, ...   \n",
       "2  [Prof, ., Dr, ., Abeba, Tesfamariam, ,, gebore...   \n",
       "3  [Hier, ist, das, Auszug, aus, dem, Protokoll, ...   \n",
       "4  [El, Sr, ., Juan, Pérez, ,, un, empresario, de...   \n",
       "\n",
       "                                                 ner  \n",
       "0  [[0, 1, person], [7, 10, organization], [23, 2...  \n",
       "1  [[0, 2, person], [43, 45, address], [38, 41, s...  \n",
       "2  [[0, 5, person], [25, 25, degree], [58, 58, de...  \n",
       "3  [[24, 25, person], [32, 32, membership number]...  \n",
       "4  [[3, 4, person], [18, 19, organization], [23, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.DataFrame(train_dataset)\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "import torch\n",
    "from gliner import GLiNERConfig, GLiNER\n",
    "from gliner.training import Trainer, TrainingArguments\n",
    "from gliner.data_processing.collator import DataCollatorWithPadding, DataCollator\n",
    "from gliner.utils import load_config_as_namespace\n",
    "from gliner.data_processing import WordsSplitter, GLiNERDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json not found in /workspaces/NER-project/models/gliner_medium-v2.1\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = GLiNER.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use it for better performance, it mimics original implementation but it's less memory efficient\n",
    "data_collator = DataCollator(model.config, data_processor=model.data_processor, prepare_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_PROJECT\"]=\"NER\"\n",
    "os.environ[\"WANDB_LOG_MODEL\"]=\"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='57' max='2209' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  57/2209 00:31 < 20:48, 1.72 it/s, Epoch 0.03/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/gliner/data_processing/processor.py:206: UserWarning: Sentence of length 503 has been truncated to 384\n",
      "  warnings.warn(f\"Sentence of length {len(tokens)} has been truncated to {max_len}\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 36\u001b[0m\n\u001b[1;32m      8\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      9\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39mMODEL_PATH,\n\u001b[1;32m     10\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-6\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m     )\n\u001b[1;32m     27\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     28\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     29\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[1;32m     34\u001b[0m )\n\u001b[0;32m---> 36\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/transformers/trainer.py:1932\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/transformers/trainer.py:2273\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   2268\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2271\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2272\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2273\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2274\u001b[0m ):\n\u001b[1;32m   2275\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2276\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# calculate number of epochs\n",
    "num_steps = 500\n",
    "batch_size = 8\n",
    "data_size = len(train_dataset)\n",
    "num_batches = data_size // batch_size\n",
    "num_epochs = max(1, num_steps // num_batches)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_PATH,\n",
    "    learning_rate=5e-6,\n",
    "    weight_decay=0.01,\n",
    "    others_lr=1e-5,\n",
    "    others_weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\", #cosine\n",
    "    warmup_ratio=0.1,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps = 500,\n",
    "    save_total_limit=10,\n",
    "    dataloader_num_workers = 0,\n",
    "    use_cpu = False,\n",
    "    report_to=\"none\",\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=model.data_processor.transformer_tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cristiano Ronaldo dos Santos Aveiro => Person\n",
      "Ballon d'Or => Award\n",
      "UEFA Men's Player of the Year Awards => Award\n",
      "European Golden Shoes => Award\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Cristiano Ronaldo dos Santos Aveiro (Portuguese pronunciation: [kɾiʃˈtjɐnu ʁɔˈnaldu]; born 5 February 1985) is a Portuguese professional footballer who plays as a forward for and captains both Saudi Pro League club Al Nassr and the Portugal national team. Widely regarded as one of the greatest players of all time, Ronaldo has won five Ballon d'Or awards,[note 3] a record three UEFA Men's Player of the Year Awards, and four European Golden Shoes, the most by a European player. He has won 33 trophies in his career, including seven league titles, five UEFA Champions Leagues, the UEFA European Championship and the UEFA Nations League. Ronaldo holds the records for most appearances (183), goals (140) and assists (42) in the Champions League, goals in the European Championship (14), international goals (128) and international appearances (205). He is one of the few players to have made over 1,200 professional career appearances, the most by an outfield player, and has scored over 850 official senior career goals for club and country, making him the top goalscorer of all time.\n",
    "\"\"\"\n",
    "\n",
    "# Labels for entity prediction\n",
    "labels = [\"Person\", \"Award\"] # for v2.1 use capital case for better performance\n",
    "\n",
    "# Perform entity prediction\n",
    "entities = model.predict_entities(text, labels, threshold=0.5)\n",
    "\n",
    "# Display predicted entities and their labels\n",
    "for entity in entities:\n",
    "    print(entity[\"text\"], \"=>\", entity[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
