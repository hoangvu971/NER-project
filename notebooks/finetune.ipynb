{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../data/synthetic-pii-ner.json'\n",
    "MODEL_PATH = '../models/gliner_medium-v2.1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-08-18 03:33:09--  https://huggingface.co/datasets/urchade/synthetic-pii-ner-mistral-v1/resolve/main/data.json\n",
      "Resolving huggingface.co (huggingface.co)... 3.162.58.119, 3.162.58.28, 3.162.58.5, ...\n",
      "Connecting to huggingface.co (huggingface.co)|3.162.58.119|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs-us-1.huggingface.co/repos/57/a8/57a8ec4f4ec288845876da262e329709a3abab15f5604211687806ff1c31f16f/78680af45ca6b1175c502db2eec441933de7383f440fc0f0bae46a72be13c0c7?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27data.json%3B+filename%3D%22data.json%22%3B&response-content-type=application%2Fjson&Expires=1724211212&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNDIxMTIxMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzU3L2E4LzU3YThlYzRmNGVjMjg4ODQ1ODc2ZGEyNjJlMzI5NzA5YTNhYmFiMTVmNTYwNDIxMTY4NzgwNmZmMWMzMWYxNmYvNzg2ODBhZjQ1Y2E2YjExNzVjNTAyZGIyZWVjNDQxOTMzZGU3MzgzZjQ0MGZjMGYwYmFlNDZhNzJiZTEzYzBjNz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=epXcm2zDfJ%7E8mDbyhRS3wwQCCpgr6zP9ryw9RrImXLYeLriy2pzN%7EIiOBEw9f2AXi09bLhGsGJy4M0%7EhHgRbUAybWWb0U1hmfo7JLELK9OugQZLo0oAMPML5aAmDUH4bsMsMusDK7AoytHOmD1wo7kqoICwhnBa9lKzW%7ENAE58Tah9W-%7EO0yzr0o4pP0vf%7Elo5cV9tsxJe5VvEgZamHbZ51v32wnVG4ombQUlz0a-13-tQMOTK1u2C824xb8lR%7EfCTtHaY8GbAFeuWQcDuxfXt3reAs3WdeLvIwyk8IuyTaeJWIOxPH2qR0GbF1FTV5AiO8oyiA-OGHpXQunAdzIIg__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
      "--2024-08-18 03:33:09--  https://cdn-lfs-us-1.huggingface.co/repos/57/a8/57a8ec4f4ec288845876da262e329709a3abab15f5604211687806ff1c31f16f/78680af45ca6b1175c502db2eec441933de7383f440fc0f0bae46a72be13c0c7?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27data.json%3B+filename%3D%22data.json%22%3B&response-content-type=application%2Fjson&Expires=1724211212&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNDIxMTIxMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zLzU3L2E4LzU3YThlYzRmNGVjMjg4ODQ1ODc2ZGEyNjJlMzI5NzA5YTNhYmFiMTVmNTYwNDIxMTY4NzgwNmZmMWMzMWYxNmYvNzg2ODBhZjQ1Y2E2YjExNzVjNTAyZGIyZWVjNDQxOTMzZGU3MzgzZjQ0MGZjMGYwYmFlNDZhNzJiZTEzYzBjNz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=epXcm2zDfJ%7E8mDbyhRS3wwQCCpgr6zP9ryw9RrImXLYeLriy2pzN%7EIiOBEw9f2AXi09bLhGsGJy4M0%7EhHgRbUAybWWb0U1hmfo7JLELK9OugQZLo0oAMPML5aAmDUH4bsMsMusDK7AoytHOmD1wo7kqoICwhnBa9lKzW%7ENAE58Tah9W-%7EO0yzr0o4pP0vf%7Elo5cV9tsxJe5VvEgZamHbZ51v32wnVG4ombQUlz0a-13-tQMOTK1u2C824xb8lR%7EfCTtHaY8GbAFeuWQcDuxfXt3reAs3WdeLvIwyk8IuyTaeJWIOxPH2qR0GbF1FTV5AiO8oyiA-OGHpXQunAdzIIg__&Key-Pair-Id=K24J24Z295AEI9\n",
      "Resolving cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)... 54.230.71.5, 54.230.71.85, 54.230.71.77, ...\n",
      "Connecting to cdn-lfs-us-1.huggingface.co (cdn-lfs-us-1.huggingface.co)|54.230.71.5|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 23300735 (22M) [application/json]\n",
      "Saving to: ‚Äòdata.json‚Äô\n",
      "\n",
      "data.json           100%[===================>]  22.22M  12.2MB/s    in 1.8s    \n",
      "\n",
      "2024-08-18 03:33:11 (12.2 MB/s) - ‚Äòdata.json‚Äô saved [23300735/23300735]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget https://huggingface.co/datasets/urchade/synthetic-pii-ner-mistral-v1/resolve/main/data.json\n",
    "! mv data.json ../data/synthetic-pii-ner.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 19635\n",
      "Dataset is shuffled...\n",
      "Dataset is splitted...\n"
     ]
    }
   ],
   "source": [
    "with open(DATA_PATH, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "print('Dataset size:', len(data))\n",
    "\n",
    "random.shuffle(data)\n",
    "print('Dataset is shuffled...')\n",
    "\n",
    "train_dataset = data[:int(len(data)*0.9)]\n",
    "test_dataset = data[int(len(data)*0.9):]\n",
    "\n",
    "print('Dataset is splitted...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>ner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Juan, P√©rez, ,, un, jugador, habitual, del, C...</td>\n",
       "      <td>[[0, 1, person], [7, 10, organization], [23, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Mme, Yoshiko, Nakamura, ,, agricultrice, de, ...</td>\n",
       "      <td>[[0, 2, person], [43, 45, address], [38, 41, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Prof, ., Dr, ., Abeba, Tesfamariam, ,, gebore...</td>\n",
       "      <td>[[0, 5, person], [25, 25, degree], [58, 58, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Hier, ist, das, Auszug, aus, dem, Protokoll, ...</td>\n",
       "      <td>[[24, 25, person], [32, 32, membership number]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[El, Sr, ., Juan, P√©rez, ,, un, empresario, de...</td>\n",
       "      <td>[[3, 4, person], [18, 19, organization], [23, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      tokenized_text  \\\n",
       "0  [Juan, P√©rez, ,, un, jugador, habitual, del, C...   \n",
       "1  [Mme, Yoshiko, Nakamura, ,, agricultrice, de, ...   \n",
       "2  [Prof, ., Dr, ., Abeba, Tesfamariam, ,, gebore...   \n",
       "3  [Hier, ist, das, Auszug, aus, dem, Protokoll, ...   \n",
       "4  [El, Sr, ., Juan, P√©rez, ,, un, empresario, de...   \n",
       "\n",
       "                                                 ner  \n",
       "0  [[0, 1, person], [7, 10, organization], [23, 2...  \n",
       "1  [[0, 2, person], [43, 45, address], [38, 41, s...  \n",
       "2  [[0, 5, person], [25, 25, degree], [58, 58, de...  \n",
       "3  [[24, 25, person], [32, 32, membership number]...  \n",
       "4  [[3, 4, person], [18, 19, organization], [23, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.DataFrame(train_dataset)\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"\n",
    "\n",
    "import torch\n",
    "from gliner import GLiNERConfig, GLiNER\n",
    "from gliner.training import Trainer, TrainingArguments\n",
    "from gliner.data_processing.collator import DataCollatorWithPadding, DataCollator\n",
    "from gliner.utils import load_config_as_namespace\n",
    "from gliner.data_processing import WordsSplitter, GLiNERDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json not found in /workspaces/NER-project/models/gliner_medium-v2.1\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "model = GLiNER.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use it for better performance, it mimics original implementation but it's less memory efficient\n",
    "data_collator = DataCollator(model.config, data_processor=model.data_processor, prepare_labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_MLFLOW_LOG_ARTIFACTS\"] = \"true\"\n",
    "os.environ[\"MLFLOW_EXPERIMENT_NAME\"] = \"gliner_medium-v2.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading \"original-fs\" failed\n",
      "Error: Cannot find module 'original-fs'\n",
      "Require stack:\n",
      "- /vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/out/server-cli.js\n",
      "\u001b[90m    at Module._resolveFilename (node:internal/modules/cjs/loader:1145:15)\u001b[39m\n",
      "\u001b[90m    at Module._load (node:internal/modules/cjs/loader:986:27)\u001b[39m\n",
      "\u001b[90m    at Module.require (node:internal/modules/cjs/loader:1233:19)\u001b[39m\n",
      "\u001b[90m    at require (node:internal/modules/helpers:179:18)\u001b[39m\n",
      "    at i (/vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/out/server-cli.js:3:98)\n",
      "    at r.load (/vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/out/server-cli.js:2:1637)\n",
      "    at h.load (/vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/out/server-cli.js:1:13958)\n",
      "    at u (/vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/out/server-cli.js:3:9338)\n",
      "    at Object.errorback (/vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/out/server-cli.js:3:9457)\n",
      "    at h.triggerErrorback (/vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/out/server-cli.js:1:14252)\n",
      "    at /vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/out/server-cli.js:1:14003\n",
      "    at r.load (/vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/out/server-cli.js:2:1654)\n",
      "    at h.load (/vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/out/server-cli.js:1:13958)\n",
      "    at u (/vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/out/server-cli.js:3:9338)\n",
      "    at l._loadModule (/vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/out/server-cli.js:3:9466)\n",
      "    at l._resolve (/vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/out/server-cli.js:4:452)\n",
      "    at l.defineModule (/vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/out/server-cli.js:3:5561)\n",
      "    at Function.p [as define] (/vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/out/server-cli.js:4:1741)\n",
      "    at out-build/bootstrap-amd.js (/vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/out/server-cli.js:4:6445)\n",
      "    at /vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/out/server-cli.js:1:132\n",
      "    at Object.<anonymous> (/vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/out/server-cli.js:4:9653)\n",
      "\u001b[90m    at Module._compile (node:internal/modules/cjs/loader:1358:14)\u001b[39m\n",
      "\u001b[90m    at Module._extensions..js (node:internal/modules/cjs/loader:1416:10)\u001b[39m\n",
      "\u001b[90m    at Module.load (node:internal/modules/cjs/loader:1208:32)\u001b[39m\n",
      "\u001b[90m    at Module._load (node:internal/modules/cjs/loader:1024:12)\u001b[39m\n",
      "\u001b[90m    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:174:12)\u001b[39m\n",
      "\u001b[90m    at node:internal/main/run_main_module:28:49\u001b[39m {\n",
      "  code: \u001b[32m'MODULE_NOT_FOUND'\u001b[39m,\n",
      "  requireStack: [\n",
      "    \u001b[32m'/vscode/vscode-server/bin/linux-x64/fee1edb8d6d72a0ddff41e5f71a671c23ed924b9/out/server-cli.js'\u001b[39m\n",
      "  ],\n",
      "  phase: \u001b[32m'loading'\u001b[39m,\n",
      "  moduleId: \u001b[32m'original-fs'\u001b[39m,\n",
      "  neededBy: [ \u001b[32m'fs'\u001b[39m ]\n",
      "}\n",
      "Here are the modules that depend on it:\n",
      "[ \u001b[32m'fs'\u001b[39m ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">                                       <span style=\"font-weight: bold\">‚ùó‚ùó‚ùó AUTHORIZATION REQUIRED ‚ùó‚ùó‚ùó</span>                                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "                                       \u001b[1m‚ùó‚ùó‚ùó AUTHORIZATION REQUIRED ‚ùó‚ùó‚ùó\u001b[0m                                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/rich/live.py:229: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/rich/live.py:229: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Open the following link in your browser to authorize the client:\n",
      "https://dagshub.com/login/oauth/authorize?state=5ecb2705-5cb9-4143-b86c-0f3a96330bf4&client_id=32b60ba385aa7cecf24046d8195a71c07dd345d9657977863b52e7748e0f0f28&middleman_request_id=31357034eb2e65fdf37922ffa4097f39e6c5358d8b805223adcda016e83ca892\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as hoangvu971\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as hoangvu971\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"hoangvu971/NER-project\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"hoangvu971/NER-project\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository hoangvu971/NER-project initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository hoangvu971/NER-project initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/08/23 02:52:48 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2024/08/23 02:52:48 INFO mlflow.tracking.fluent: Autologging successfully enabled for transformers.\n"
     ]
    }
   ],
   "source": [
    "import dagshub\n",
    "import mlflow\n",
    "dagshub.init(repo_owner='hoangvu971', repo_name='NER-project', mlflow=True)\n",
    "mlflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "2024/08/23 02:53:08 INFO mlflow.tracking.fluent: Experiment with name 'gliner_medium-v2.1' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='36' max='2209' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  36/2209 02:08 < 2:16:37, 0.27 it/s, Epoch 0.02/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 36\u001b[0m\n\u001b[1;32m      8\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      9\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39mMODEL_PATH,\n\u001b[1;32m     10\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5e-6\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m     report_to\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlflow\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m     )\n\u001b[1;32m     27\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     28\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     29\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[1;32m     34\u001b[0m )\n\u001b[0;32m---> 36\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:580\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    578\u001b[0m     patch_function\u001b[38;5;241m.\u001b[39mcall(call_original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 580\u001b[0m     \u001b[43mpatch_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall_original\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m session\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msucceeded\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    584\u001b[0m try_log_autologging_event(\n\u001b[1;32m    585\u001b[0m     AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_patch_function_success,\n\u001b[1;32m    586\u001b[0m     session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m     kwargs,\n\u001b[1;32m    591\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/mlflow/transformers/__init__.py:2795\u001b[0m, in \u001b[0;36mautolog.<locals>.train\u001b[0;34m(original, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2793\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(original, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2794\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m disable_discrete_autologging(DISABLED_ANCILLARY_FLAVOR_AUTOLOGGING):\n\u001b[0;32m-> 2795\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:561\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[0;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m         original_result \u001b[38;5;241m=\u001b[39m original(\u001b[38;5;241m*\u001b[39m_og_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_og_kwargs)\n\u001b[1;32m    559\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n\u001b[0;32m--> 561\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_original_fn_with_event_logging\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_original_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:496\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[0;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    489\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_start,\n\u001b[1;32m    490\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    494\u001b[0m         og_kwargs,\n\u001b[1;32m    495\u001b[0m     )\n\u001b[0;32m--> 496\u001b[0m     original_fn_result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mog_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mog_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    498\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    499\u001b[0m         AutologgingEventLogger\u001b[38;5;241m.\u001b[39mget_logger()\u001b[38;5;241m.\u001b[39mlog_original_function_success,\n\u001b[1;32m    500\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    504\u001b[0m         og_kwargs,\n\u001b[1;32m    505\u001b[0m     )\n\u001b[1;32m    506\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_fn_result\n",
      "File \u001b[0;32m/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:558\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[0;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;66;03m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;66;03m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;66;03m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;66;03m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[1;32m    555\u001b[0m     disable_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    556\u001b[0m     reroute_warnings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    557\u001b[0m ):\n\u001b[0;32m--> 558\u001b[0m     original_result \u001b[38;5;241m=\u001b[39m \u001b[43moriginal\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_og_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_og_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m original_result\n",
      "File \u001b[0;32m/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/transformers/trainer.py:1932\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1932\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1936\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1937\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/transformers/trainer.py:2273\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   2268\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2271\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2272\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2273\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2274\u001b[0m ):\n\u001b[1;32m   2275\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2276\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2277\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# calculate number of epochs\n",
    "num_steps = 500\n",
    "batch_size = 8\n",
    "data_size = len(train_dataset)\n",
    "num_batches = data_size // batch_size\n",
    "num_epochs = max(1, num_steps // num_batches)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_PATH,\n",
    "    learning_rate=5e-6,\n",
    "    weight_decay=0.01,\n",
    "    others_lr=1e-5,\n",
    "    others_weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\", #cosine\n",
    "    warmup_ratio=0.1,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    save_steps = 500,\n",
    "    save_total_limit=10,\n",
    "    dataloader_num_workers = 0,\n",
    "    use_cpu = False,\n",
    "    report_to=\"mlflow\",\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=model.data_processor.transformer_tokenizer,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cristiano Ronaldo dos Santos Aveiro => Person\n",
      "Ballon d'Or => Award\n",
      "UEFA Men's Player of the Year Awards => Award\n",
      "European Golden Shoes => Award\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Cristiano Ronaldo dos Santos Aveiro (Portuguese pronunciation: [k…æi ÉÀàtj…ênu  Å…îÀànaldu]; born 5 February 1985) is a Portuguese professional footballer who plays as a forward for and captains both Saudi Pro League club Al Nassr and the Portugal national team. Widely regarded as one of the greatest players of all time, Ronaldo has won five Ballon d'Or awards,[note 3] a record three UEFA Men's Player of the Year Awards, and four European Golden Shoes, the most by a European player. He has won 33 trophies in his career, including seven league titles, five UEFA Champions Leagues, the UEFA European Championship and the UEFA Nations League. Ronaldo holds the records for most appearances (183), goals (140) and assists (42) in the Champions League, goals in the European Championship (14), international goals (128) and international appearances (205). He is one of the few players to have made over 1,200 professional career appearances, the most by an outfield player, and has scored over 850 official senior career goals for club and country, making him the top goalscorer of all time.\n",
    "\"\"\"\n",
    "\n",
    "# Labels for entity prediction\n",
    "labels = [\"Person\", \"Award\"] # for v2.1 use capital case for better performance\n",
    "\n",
    "# Perform entity prediction\n",
    "entities = model.predict_entities(text, labels, threshold=0.5)\n",
    "\n",
    "# Display predicted entities and their labels\n",
    "for entity in entities:\n",
    "    print(entity[\"text\"], \"=>\", entity[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12884246528"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_properties(0).total_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
