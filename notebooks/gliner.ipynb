{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Fetching 4 files: 100%|██████████| 4/4 [00:00<00:00, 36873.00it/s]\n",
      "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:562: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from gliner import GLiNER\n",
    "\n",
    "model = GLiNER.from_pretrained(\"urchade/gliner_medium-v2.1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"../models/gliner_medium-v2.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json not found in /workspaces/NER-project/models/gliner_medium-v2.1\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model = GLiNER.from_pretrained(\"../models/gliner_medium-v2.1\", load_onnx=True, load_tokenizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_SAVE_PATH = \"../models/gliner_medium-v2.1/model.onnx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "text = \"ONNX is an open-source format designed to enable the interoperability of AI models across various frameworks and tools.\"\n",
    "labels = ['format', 'model', 'tool', 'cat']\n",
    "\n",
    "inputs, _ = model.prepare_model_inputs([text], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:547: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.tensor(mid - 1).type_as(relative_pos),\n",
      "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:551: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  torch.ceil(torch.log(abs_pos / mid) / torch.log(torch.tensor((max_position - 1) / mid)) * (mid - 1)) + mid\n",
      "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:710: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  scale = torch.sqrt(torch.tensor(query_layer.size(-1), dtype=torch.float) * scale_factor)\n",
      "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:710: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scale = torch.sqrt(torch.tensor(query_layer.size(-1), dtype=torch.float) * scale_factor)\n",
      "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:785: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  scale = torch.sqrt(torch.tensor(pos_key_layer.size(-1), dtype=torch.float) * scale_factor)\n",
      "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:785: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scale = torch.sqrt(torch.tensor(pos_key_layer.size(-1), dtype=torch.float) * scale_factor)\n",
      "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:797: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  scale = torch.sqrt(torch.tensor(pos_query_layer.size(-1), dtype=torch.float) * scale_factor)\n",
      "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:797: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  scale = torch.sqrt(torch.tensor(pos_query_layer.size(-1), dtype=torch.float) * scale_factor)\n",
      "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:798: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if key_layer.size(-2) != query_layer.size(-2):\n",
      "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/transformers/models/deberta_v2/modeling_deberta_v2.py:105: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  output = input.masked_fill(rmask, torch.tensor(torch.finfo(input.dtype).min))\n",
      "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:5857: UserWarning: Exporting aten::index operator of advanced indexing in opset 14 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
      "  warnings.warn(\n",
      "[W shape_type_inference.cpp:1974] Warning: The shape inference of prim::PackPadded type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "[W shape_type_inference.cpp:1974] Warning: The shape inference of prim::PackPadded type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n",
      "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/torch/onnx/symbolic_opset9.py:4662: UserWarning: Exporting a model to ONNX with a batch_size other than 1, with a variable length with LSTM can cause an error when running the ONNX model with a different batch size. Make sure to save the model with a batch size of 1, or define the initial states (h0/c0) as inputs of the model. \n",
      "  warnings.warn(\n",
      "[W shape_type_inference.cpp:1974] Warning: The shape inference of prim::PadPacked type is missing, so it may result in wrong shape inference for the exported graph. Please consider adding it in symbolic function. (function UpdateReliable)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if model.config.span_mode == 'token_level':\n",
    "    all_inputs =  (inputs['input_ids'], inputs['attention_mask'], \n",
    "                    inputs['words_mask'], inputs['text_lengths'])\n",
    "    input_names = ['input_ids', 'attention_mask', 'words_mask', 'text_lengths']\n",
    "    dynamic_axes={\n",
    "        \"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"words_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"text_lengths\": {0: \"batch_size\", 1: \"value\"},\n",
    "        \"logits\": {0: \"position\", 1: \"batch_size\", 2: \"sequence_length\", 3: \"num_classes\"},\n",
    "    }\n",
    "else:\n",
    "    all_inputs =  (inputs['input_ids'], inputs['attention_mask'], \n",
    "                    inputs['words_mask'], inputs['text_lengths'],\n",
    "                    inputs['span_idx'], inputs['span_mask'])\n",
    "    input_names = ['input_ids', 'attention_mask', 'words_mask', 'text_lengths', 'span_idx', 'span_mask']\n",
    "    dynamic_axes={\n",
    "        \"input_ids\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"words_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "        \"text_lengths\": {0: \"batch_size\", 1: \"value\"},\n",
    "        \"span_idx\": {0: \"batch_size\", 1: \"num_spans\", 2: \"idx\"},\n",
    "        \"span_mask\": {0: \"batch_size\", 1: \"num_spans\"},\n",
    "        \"logits\": {0: \"batch_size\", 1: \"sequence_length\", 2: \"num_spans\", 3: \"num_classes\"},\n",
    "    }\n",
    "print('Converting the model...')\n",
    "torch.onnx.export(\n",
    "    model.model,\n",
    "    all_inputs,\n",
    "    f=ONNX_SAVE_PATH,\n",
    "    input_names=input_names,\n",
    "    output_names=[\"logits\"],\n",
    "    dynamic_axes=dynamic_axes,\n",
    "    opset_version=14,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantizing the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# #quantize model\n",
    "# import os\n",
    "# from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "# quantized_save_path = (\"../models/gliner_medium-v2.1/model_quantized.onnx\")\n",
    "# # Quantize the ONNX model\n",
    "# print(\"Quantizing the model...\")\n",
    "# quantize_dynamic(\n",
    "#     ONNX_SAVE_PATH,  # Input model\n",
    "#     quantized_save_path,  # Output model\n",
    "#     weight_type=QuantType.QUInt8  # Quantize weights to 8-bit integers\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/training-pipeline/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "config.json not found in /workspaces/NER-project/models/gliner_medium-v2.1\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from gliner import GLiNER\n",
    "model = GLiNER.from_pretrained(\"../models/gliner_medium-v2.1\", load_onnx=True, load_tokenizer=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "text2 = \"My name is Tom, I live in New York and my girlfriend's name is Elaine. Our parents live in Viet Nam, Nha Trang city, and their names are Que and Mai\"\n",
    "labels = ['Person', 'Place']\n",
    "\n",
    "inputs, raw_batch = model.prepare_model_inputs([text2], labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trilby => character\n",
      "Moscow => location\n",
      "January 25/February 6 => date\n",
      "1870 => date\n",
      "Moscow => location\n",
      "Polina Karpakova => actor\n",
      "Trilby => character\n",
      "Ludiia Geiten => actor\n",
      "Miranda => character\n",
      "January 17–29, 1871 => date\n",
      "St. Petersburg => location\n",
      "Adèle Grantzow => actor\n",
      "Trilby => character\n",
      "Lev Ivanov => actor\n",
      "Count Leopold => character\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Libretto by Marius Petipa, based on the 1822 novella ``Trilby, ou Le Lutin d'Argail`` by Charles Nodier, first presented by the Ballet of the Moscow Imperial Bolshoi Theatre on January 25/February 6 (Julian/Gregorian calendar dates), 1870, in Moscow with Polina Karpakova as Trilby and Ludiia Geiten as Miranda and restaged by Petipa for the Imperial Ballet at the Imperial Bolshoi Kamenny Theatre on January 17–29, 1871 in St. Petersburg with Adèle Grantzow as Trilby and Lev Ivanov as Count Leopold.\n",
    "\"\"\"\n",
    "\n",
    "labels = [\"person\", \"book\", \"location\", \"date\", \"actor\", \"character\"]\n",
    "\n",
    "entities = model.predict_entities(text, labels, threshold=0.4)\n",
    "\n",
    "output_dict = {}\n",
    "\n",
    "for entity in entities:\n",
    "    output_dict[entity[\"text\"]] = entity[\"label\"]\n",
    "\n",
    "for entity in entities:\n",
    "    print(entity[\"text\"], \"=>\", entity[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Trilby': 'character',\n",
       " 'Moscow': 'location',\n",
       " 'January 25/February 6': 'date',\n",
       " '1870': 'date',\n",
       " 'Polina Karpakova': 'actor',\n",
       " 'Ludiia Geiten': 'actor',\n",
       " 'Miranda': 'character',\n",
       " 'January 17–29, 1871': 'date',\n",
       " 'St. Petersburg': 'location',\n",
       " 'Adèle Grantzow': 'actor',\n",
       " 'Lev Ivanov': 'actor',\n",
       " 'Count Leopold': 'character'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "ort_sess = ort.InferenceSession('../models/gliner_medium-v2.1/model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "outputs = ort_sess.run(None, {'input_ids': inputs['input_ids'].numpy(),\n",
    "                            'attention_mask': inputs['attention_mask'].numpy(),\n",
    "                            'words_mask': inputs['words_mask'].numpy(),\n",
    "                            'text_lengths': inputs['text_lengths'].numpy(),\n",
    "                            'span_idx': inputs['span_idx'].numpy(),\n",
    "                            'span_mask': inputs['span_mask'].numpy(),\n",
    "                            })[0]\n",
    "outputs = torch.from_numpy(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 3, 'Person', 0.9672063589096069),\n",
       " (8, 9, 'Place', 0.8985015153884888),\n",
       " (17, 17, 'Person', 0.9670381546020508),\n",
       " (23, 24, 'Place', 0.9371719360351562),\n",
       " (26, 28, 'Place', 0.9003996849060059),\n",
       " (34, 34, 'Person', 0.8820420503616333),\n",
       " (36, 36, 'Person', 0.7397370934486389)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model.decoder.decode(\n",
    "            raw_batch[\"tokens\"],\n",
    "            raw_batch[\"id_to_classes\"],\n",
    "            outputs,\n",
    "            flat_ner=True,\n",
    "            threshold=0.5,\n",
    "            multi_label=False,\n",
    "        )[0]\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Tom'] => Person\n",
      "['New', 'York'] => Place\n",
      "['Elaine'] => Person\n",
      "['Viet', 'Nam'] => Place\n",
      "['Nha', 'Trang', 'city'] => Place\n",
      "['Que'] => Person\n",
      "['Mai'] => Person\n"
     ]
    }
   ],
   "source": [
    "texts = raw_batch['tokens'][0]\n",
    "\n",
    "for output in outputs:\n",
    "    start, end = output[:2]\n",
    "    entity = output[2]\n",
    "    print(f\"{texts[start:end+1]} => {entity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: {'Trilby': 'character', 'Moscow': 'location', 'January 25/February 6': 'date', '1870': 'date', 'Polina Karpakova': 'actor', 'Ludiia Geiten': 'actor', 'Miranda': 'character', 'January 17–29, 1871': 'date', 'St. Petersburg': 'location', 'Adèle Grantzow': 'actor', 'Lev Ivanov': 'actor', 'Count Leopold': 'character'}\n"
     ]
    }
   ],
   "source": [
    "import bentoml\n",
    "\n",
    "text = \"\"\"\n",
    "Libretto by Marius Petipa, based on the 1822 novella ``Trilby, ou Le Lutin d'Argail`` by Charles Nodier, first presented by the Ballet of the Moscow Imperial Bolshoi Theatre on January 25/February 6 (Julian/Gregorian calendar dates), 1870, in Moscow with Polina Karpakova as Trilby and Ludiia Geiten as Miranda and restaged by Petipa for the Imperial Ballet at the Imperial Bolshoi Kamenny Theatre on January 17–29, 1871 in St. Petersburg with Adèle Grantzow as Trilby and Lev Ivanov as Count Leopold.\n",
    "\"\"\"\n",
    "\n",
    "labels = [\"person\", \"book\", \"location\", \"date\", \"actor\", \"character\"]\n",
    "with bentoml.SyncHTTPClient('http://localhost:3000') as client:\n",
    "    output_dict: dict = client.extract(text, labels)\n",
    "    print(f\"Result: {output_dict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "training-pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
